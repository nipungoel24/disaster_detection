{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c91998b",
   "metadata": {},
   "source": [
    "# **Chipping Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c5e995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import numpy as np\n",
    "import torch\n",
    "from rasterio.merge import merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the input and output chip size\n",
    "CHIP_SIZE = 512 \n",
    "\n",
    "def chip_image(input_filepath, output_directory):\n",
    "    \"\"\"Cuts a large GeoTIFF into smaller chips.\"\"\"\n",
    "    with rasterio.open(input_filepath) as src:\n",
    "        # Get the width and height of the entire image\n",
    "        width = src.width\n",
    "        height = src.height\n",
    "        \n",
    "        count = 0\n",
    "        # Loop through the image in chunks of CHIP_SIZE\n",
    "        for i in range(0, height, CHIP_SIZE):\n",
    "            for j in range(0, width, CHIP_SIZE):\n",
    "                \n",
    "                # Define the window (area) to read from the large image\n",
    "                # The window accounts for the edges where the size might be less than CHIP_SIZE\n",
    "                window = Window(j, i, min(CHIP_SIZE, width - j), min(CHIP_SIZE, height - i))\n",
    "                transform = src.window_transform(window)\n",
    "                \n",
    "                # Read the data from the defined window\n",
    "                chip_data = src.read(1, window=window)\n",
    "\n",
    "                # Skip if the chip contains mostly \"no data\" values (e.g., beyond your AOI)\n",
    "                if np.sum(chip_data == src.nodata) / chip_data.size > 0.95:\n",
    "                    continue\n",
    "\n",
    "                # Update the metadata profile for the new small chip file\n",
    "                profile = src.profile\n",
    "                profile.update({\n",
    "                    'height': window.height,\n",
    "                    'width': window.width,\n",
    "                    'transform': transform\n",
    "                })\n",
    "                \n",
    "                # Save the chip\n",
    "                output_path = f\"{output_directory}/{src.name.split('/')[-1].replace('.tif', '')}_chip_{count}.tif\"\n",
    "                with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "                    dst.write(chip_data, 1)\n",
    "                \n",
    "                count += 1\n",
    "                \n",
    "    print(f\"Successfully chipped {input_filepath} into {count} tiles.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b332e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully prepared 5 district pairs for chipping.\n",
      "\n",
      "--- Chipping files for Barpeta ---\n",
      "✅ Successfully chipped C:\\Kaam_Dhanda\\Minor_Project\\Old Images\\Barpeta_PreFlood_Image.tif into 96 tiles.\n",
      "✅ Successfully chipped C:\\Kaam_Dhanda\\Minor_Project\\Old Images\\Barpeta_PostFlood_Image.tif into 96 tiles.\n",
      "\n",
      "--- Chipping files for Dhemaji ---\n",
      "✅ Successfully chipped C:\\Kaam_Dhanda\\Minor_Project\\Old Images\\Dhemaji_PreFlood_Image.tif into 104 tiles.\n",
      "✅ Successfully chipped C:\\Kaam_Dhanda\\Minor_Project\\Old Images\\Dhemaji_PostFlood_Image.tif into 104 tiles.\n",
      "\n",
      "--- Chipping files for Lakhimpur ---\n",
      "✅ Successfully chipped C:\\Kaam_Dhanda\\Minor_Project\\Old Images\\Lakhimpur_PreFlood_Image.tif into 324 tiles.\n",
      "✅ Successfully chipped C:\\Kaam_Dhanda\\Minor_Project\\Old Images\\Lakhimpur_PostFlood_Image.tif into 324 tiles.\n",
      "\n",
      "--- Chipping files for Nalbari ---\n",
      "✅ Successfully chipped C:\\Kaam_Dhanda\\Minor_Project\\Old Images\\Nalbari_PreFlood_Image.tif into 80 tiles.\n",
      "✅ Successfully chipped C:\\Kaam_Dhanda\\Minor_Project\\Old Images\\Nalbari_PostFlood_Image.tif into 80 tiles.\n",
      "\n",
      "--- Chipping files for Sonitpur ---\n",
      "✅ Successfully chipped C:\\Kaam_Dhanda\\Minor_Project\\Old Images\\Sonitpur_PreFlood_Image.tif into 198 tiles.\n",
      "✅ Successfully chipped C:\\Kaam_Dhanda\\Minor_Project\\Old Images\\Sonitpur_PostFlood_Image.tif into 198 tiles.\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# GLOBAL CONFIGURATION\n",
    "# =================================================================\n",
    "\n",
    "# IMPORTANT: Use 'r' strings for Windows paths to avoid SyntaxWarnings/Errors\n",
    "TIF_DIR = r'C:\\Kaam_Dhanda\\Minor_Project\\Old Images' \n",
    "OUTPUT_CHIPS_DIR = r'C:\\Kaam_Dhanda\\Minor_Project\\Output_chips' \n",
    "\n",
    "# List of districts to process\n",
    "DISTRICTS = ['Barpeta', 'Dhemaji', 'Lakhimpur', 'Nalbari', 'Sonitpur']\n",
    "CHIP_SIZE = 512 # Standard size for deep learning input (e.g., 512x512 pixels)\n",
    "\n",
    "\n",
    "# =================================================================\n",
    "# CHIPPING FUNCTION (Core Logic)\n",
    "# =================================================================\n",
    "\n",
    "def chip_image(input_filepath, output_directory):\n",
    "    \"\"\"Cuts a large GeoTIFF into smaller, non-overlapping chips.\"\"\"\n",
    "    \n",
    "    # 1. Safely open the input image\n",
    "    try:\n",
    "        src = rasterio.open(input_filepath)\n",
    "    except rasterio.RasterioIOError as e:\n",
    "        print(f\"Error opening input file {input_filepath}: {e}\")\n",
    "        return\n",
    "\n",
    "    width = src.width\n",
    "    height = src.height\n",
    "    count = 0\n",
    "    \n",
    "    # Loop through the image in chunks of CHIP_SIZE\n",
    "    for i in range(0, height, CHIP_SIZE):\n",
    "        for j in range(0, width, CHIP_SIZE):\n",
    "            \n",
    "            # Define the window (area) to read from the large image\n",
    "            window = Window(j, i, min(CHIP_SIZE, width - j), min(CHIP_SIZE, height - i))\n",
    "            transform = src.window_transform(window)\n",
    "            \n",
    "            # Read the data from the defined window (assuming single band: 'VV')\n",
    "            chip_data = src.read(1, window=window)\n",
    "\n",
    "            # Skip if the chip contains mostly 'no data' values (e.g., beyond your AOI)\n",
    "            if np.sum(chip_data == src.nodata) / chip_data.size > 0.95:\n",
    "                continue\n",
    "\n",
    "            # Update the metadata profile for the new small chip file\n",
    "            profile = src.profile\n",
    "            profile.update({\n",
    "                'height': window.height,\n",
    "                'width': window.width,\n",
    "                'transform': transform,\n",
    "                'count': 1, # Ensure the profile reflects a single band\n",
    "                'compress': 'LZW' # Optional: Add compression to reduce chip size\n",
    "            })\n",
    "            \n",
    "            # --- CRITICAL FIX: Robust Output Path Construction ---\n",
    "            # 1. Get the base filename (e.g., 'Barpeta_PreFlood_Image.tif')\n",
    "            base_filename = os.path.basename(input_filepath)\n",
    "            \n",
    "            # 2. Remove the '.tif' extension for the chip name stem\n",
    "            file_stem = base_filename.replace('.tif', '')\n",
    "\n",
    "            # 3. Construct the final output path using os.path.join()\n",
    "            chip_filename = f'{file_stem}_chip_{count}.tif'\n",
    "            output_path = os.path.join(output_directory, chip_filename)\n",
    "            \n",
    "            # 4. Save the chip\n",
    "            try:\n",
    "                with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "                    dst.write(chip_data, 1)\n",
    "                count += 1\n",
    "            except rasterio.RasterioIOError as e:\n",
    "                 print(f\"Failed to write chip {output_path}: {e}\")\n",
    "\n",
    "    src.close()\n",
    "    print(f\"✅ Successfully chipped {input_filepath} into {count} tiles.\")\n",
    "\n",
    "\n",
    "# =================================================================\n",
    "# MAIN EXECUTION LOGIC\n",
    "# =================================================================\n",
    "\n",
    "files_to_chip = {}\n",
    "\n",
    "# --- Generate File Pairs ---\n",
    "for district in DISTRICTS:\n",
    "    pre_file = os.path.join(TIF_DIR, f'{district}_PreFlood_Image.tif')\n",
    "    post_file = os.path.join(TIF_DIR, f'{district}_PostFlood_Image.tif')\n",
    "    \n",
    "    if os.path.exists(pre_file) and os.path.exists(post_file):\n",
    "        files_to_chip[district] = {\n",
    "            'pre_flood': pre_file,\n",
    "            'post_flood': post_file\n",
    "        }\n",
    "    else:\n",
    "        print(f\"⚠️ Skipping {district}: One or both primary files were not found.\")\n",
    "        \n",
    "print(f\"Successfully prepared {len(files_to_chip)} district pairs for chipping.\")\n",
    "\n",
    "\n",
    "# --- Run Chipping Process ---\n",
    "for district, files in files_to_chip.items():\n",
    "    print(f\"\\n--- Chipping files for {district} ---\")\n",
    "    \n",
    "    # Define the output directories\n",
    "    pre_output_dir = os.path.join(OUTPUT_CHIPS_DIR, district, 'pre_flood')\n",
    "    post_output_dir = os.path.join(OUTPUT_CHIPS_DIR, district, 'post_flood')\n",
    "\n",
    "    # Create the output directories if they don't exist\n",
    "    os.makedirs(pre_output_dir, exist_ok=True)\n",
    "    os.makedirs(post_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Run chipping for the pre-flood image\n",
    "    chip_image(\n",
    "        input_filepath=files['pre_flood'],\n",
    "        output_directory=pre_output_dir\n",
    "    )\n",
    "    \n",
    "    # Run chipping for the post-flood image\n",
    "    chip_image(\n",
    "        input_filepath=files['post_flood'],\n",
    "        output_directory=post_output_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337e42fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch pre-processing from: C:\\Kaam_Dhanda\\Minor_Project\\Output_chips\n",
      "\n",
      "--- Processing District: Barpeta ---\n",
      "\n",
      "--- Processing District: Dhemaji ---\n",
      "\n",
      "--- Processing District: Lakhimpur ---\n",
      "\n",
      "--- Processing District: Nalbari ---\n",
      "\n",
      "--- Processing District: Sonitpur ---\n",
      "\n",
      "=======================================================\n",
      "✅ Batch Pre-processing Complete.\n",
      "=======================================================\n",
      "District: Barpeta\n",
      "  pre_flood: 96 chips, each with shape torch.Size([1, 1, 512, 512])\n",
      "  post_flood: 96 chips, each with shape torch.Size([1, 1, 512, 512])\n",
      "District: Dhemaji\n",
      "  pre_flood: 104 chips, each with shape torch.Size([1, 1, 512, 512])\n",
      "  post_flood: 104 chips, each with shape torch.Size([1, 1, 512, 512])\n",
      "District: Lakhimpur\n",
      "  pre_flood: 324 chips, each with shape torch.Size([1, 1, 512, 512])\n",
      "  post_flood: 324 chips, each with shape torch.Size([1, 1, 512, 512])\n",
      "District: Nalbari\n",
      "  pre_flood: 80 chips, each with shape torch.Size([1, 1, 512, 512])\n",
      "  post_flood: 80 chips, each with shape torch.Size([1, 1, 512, 512])\n",
      "District: Sonitpur\n",
      "  pre_flood: 198 chips, each with shape torch.Size([1, 1, 512, 512])\n",
      "  post_flood: 198 chips, each with shape torch.Size([1, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# =======================================================================\n",
    "# CONFIGURATION\n",
    "# =======================================================================\n",
    "\n",
    "# IMPORTANT: SET YOUR ROOT DIRECTORY HERE\n",
    "ROOT_CHIPS_DIR = r'C:\\Kaam_Dhanda\\Minor_Project\\Output_chips'\n",
    "\n",
    "# Sentinel-1 Normalization Parameters for VV (based on common practice)\n",
    "# NOTE: These are general values. For maximum accuracy, check the specific\n",
    "# Prithvi-600m documentation for its exact SAR data normalization.\n",
    "SAR_NORM_MEAN = -15.0  # Common mean for VV dB values\n",
    "SAR_NORM_STD = 5.0    # Common standard deviation for VV dB values\n",
    "\n",
    "# Dictionary to store all processed tensors\n",
    "processed_tensors = {}\n",
    "\n",
    "# =======================================================================\n",
    "# CORE PROCESSING FUNCTION\n",
    "# =======================================================================\n",
    "\n",
    "def preprocess_sar_chip(file_path, sar_mean, sar_std):\n",
    "    \"\"\"\n",
    "    Reads a single-band SAR GeoTIFF, standardizes it, and converts it\n",
    "    to a PyTorch Tensor (1, C=1, H, W) for model inference.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with rasterio.open(file_path) as src:\n",
    "            # Read the single band (VV)\n",
    "            data = src.read(1).astype(np.float32)\n",
    "            \n",
    "            # Check for empty data / no-data values\n",
    "            if np.all(data == src.nodata):\n",
    "                return None\n",
    "\n",
    "    except rasterio.RasterioIOError:\n",
    "        print(f\"Error: Could not open or read {file_path}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    # 1. Standardization (Z-Score Normalization)\n",
    "    # Apply Z-score: (Data - Mean) / Std Dev\n",
    "    normalized_data = (data - sar_mean) / sar_std\n",
    "\n",
    "    # 2. Convert to PyTorch Tensor\n",
    "    # Reshape from (H, W) to (C, H, W) -> (1, H, W)\n",
    "    tensor = torch.from_numpy(normalized_data).unsqueeze(0)\n",
    "    \n",
    "    # Add a batch dimension, making the shape (1, C, H, W) -> (1, 1, H, W)\n",
    "    tensor = tensor.unsqueeze(0) \n",
    "\n",
    "    return tensor\n",
    "\n",
    "# =======================================================================\n",
    "# BATCH EXECUTION\n",
    "# =======================================================================\n",
    "\n",
    "print(f\"Starting batch pre-processing from: {ROOT_CHIPS_DIR}\")\n",
    "\n",
    "# Iterate through all district folders (Barpeta, Dhemaji, etc.)\n",
    "for district_name in os.listdir(ROOT_CHIPS_DIR):\n",
    "    district_path = os.path.join(ROOT_CHIPS_DIR, district_name)\n",
    "    \n",
    "    if not os.path.isdir(district_path):\n",
    "        continue\n",
    "\n",
    "    processed_tensors[district_name] = {'pre_flood': [], 'post_flood': []}\n",
    "    print(f\"\\n--- Processing District: {district_name} ---\")\n",
    "\n",
    "    # Iterate through 'pre_flood' and 'post_flood' folders\n",
    "    for phase in ['pre_flood', 'post_flood']:\n",
    "        phase_path = os.path.join(district_path, phase)\n",
    "        \n",
    "        if not os.path.isdir(phase_path):\n",
    "            continue\n",
    "\n",
    "        # Process all .tif files (image chips) in the phase folder\n",
    "        for chip_filename in os.listdir(phase_path):\n",
    "            if chip_filename.endswith('.tif'):\n",
    "                chip_file_path = os.path.join(phase_path, chip_filename)\n",
    "                \n",
    "                # Run the core pre-processing function\n",
    "                tensor = preprocess_sar_chip(\n",
    "                    chip_file_path, SAR_NORM_MEAN, SAR_NORM_STD\n",
    "                )\n",
    "                \n",
    "                if tensor is not None:\n",
    "                    # Store the resulting tensor\n",
    "                    processed_tensors[district_name][phase].append(tensor)\n",
    "                    # print(f\"    Processed: {chip_filename}\")\n",
    "\n",
    "# =======================================================================\n",
    "# FINAL CHECK\n",
    "# =======================================================================\n",
    "\n",
    "print(\"\\n=======================================================\")\n",
    "print(\"✅ Batch Pre-processing Complete.\")\n",
    "print(\"=======================================================\")\n",
    "\n",
    "# Print the final structure for verification\n",
    "for district, phases in processed_tensors.items():\n",
    "    print(f\"District: {district}\")\n",
    "    for phase, tensors in phases.items():\n",
    "        if tensors:\n",
    "            # Check the shape of the first tensor in the list\n",
    "            print(f\"  {phase}: {len(tensors)} chips, each with shape {tensors[0].shape}\")\n",
    "        else:\n",
    "            print(f\"  {phase}: 0 chips found.\")\n",
    "\n",
    "# The 'processed_tensors' dictionary now holds all your data ready for the Prithvi model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3160305f",
   "metadata": {},
   "source": [
    "## **run the temporal AI inference and then stitch the predictions back together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87212e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_chip_pair(pre_path, post_path):\n",
    "    with rasterio.open(pre_path) as src_pre, rasterio.open(post_path) as src_post:\n",
    "        # Load data as NumPy arrays (assuming single band, VV polarization)\n",
    "        pre_chip = src_pre.read(1)\n",
    "        post_chip = src_post.read(1)\n",
    "        \n",
    "        # Stack them to create the temporal input (e.g., shape: 2, 512, 512)\n",
    "        temporal_input = np.stack([pre_chip, post_chip], axis=0)\n",
    "        \n",
    "        # Convert to PyTorch Tensor, add a batch dimension (1), and move to GPU (if available)\n",
    "        tensor_input = torch.from_numpy(temporal_input).float().unsqueeze(0)\n",
    "        \n",
    "        # Store the geospatial profile for later stitching\n",
    "        profile = src_pre.profile\n",
    "        \n",
    "    return tensor_input, profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3fb674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_inference_and_save(pre_path, post_path, output_mask_dir):\n",
    "    tensor_input, profile = prepare_chip_pair(pre_path, post_path)\n",
    "    \n",
    "    # 1. Run the prediction\n",
    "    # model.eval() is required for inference mode\n",
    "    with torch.no_grad():\n",
    "        # output is typically a logit map (e.g., shape: 1, num_classes, 512, 512)\n",
    "        output_logits = model(tensor_input) \n",
    "        \n",
    "    # 2. Get the final classification (0 or 1)\n",
    "    # This finds the class with the highest probability (e.g., 0=not-flood, 1=flood)\n",
    "    # Reshape and convert back to a NumPy array (shape: 512, 512)\n",
    "    predicted_mask_tensor = torch.argmax(output_logits, dim=1).squeeze().cpu()\n",
    "    predicted_mask_array = predicted_mask_tensor.numpy().astype(rasterio.uint8)\n",
    "    \n",
    "    # 3. Save the prediction mask\n",
    "    chip_filename = os.path.basename(pre_path).replace('PreFlood_Image', 'Flood_Mask')\n",
    "    output_path = os.path.join(output_mask_dir, chip_filename)\n",
    "    \n",
    "    # Update profile to reflect the new data type (binary mask)\n",
    "    profile.update(dtype=rasterio.uint8, count=1) \n",
    "    \n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        dst.write(predicted_mask_array, 1)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4226179",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stitch_masks(mask_dir, district_name, final_output_dir):\n",
    "    \"\"\"Stitches all predicted flood mask chips into a single GeoTIFF.\"\"\"\n",
    "    \n",
    "    mask_files = [os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith('.tif')]\n",
    "    \n",
    "    # Open all mask datasets\n",
    "    sources = [rasterio.open(f) for f in mask_files]\n",
    "    \n",
    "    # Use rasterio.merge to create a mosaic\n",
    "    stitched_array, out_transform = merge(sources)\n",
    "    \n",
    "    # Get the metadata from the first source file\n",
    "    out_meta = sources[0].profile.copy()\n",
    "    \n",
    "    # Update the metadata for the merged output\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": stitched_array.shape[1],\n",
    "        \"width\": stitched_array.shape[2],\n",
    "        \"transform\": out_transform,\n",
    "        \"count\": 1,\n",
    "        \"dtype\": 'uint8'\n",
    "    })\n",
    "    \n",
    "    # Write the final stitched GeoTIFF\n",
    "    final_output_path = os.path.join(final_output_dir, f'{district_name}_Final_Flood_Mask.tif')\n",
    "    with rasterio.open(final_output_path, \"w\", **out_meta) as dest:\n",
    "        dest.write(stitched_array)\n",
    "        \n",
    "    # Close all source files\n",
    "    for src in sources:\n",
    "        src.close()\n",
    "        \n",
    "    print(f\"✅ Final stitched mask saved to: {final_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e52637c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minor_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
